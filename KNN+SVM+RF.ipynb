{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea22e470",
   "metadata": {},
   "source": [
    "MH4510 Project: Brain Tumor Classification\n",
    "\n",
    "Models included: \n",
    "KNN, Support Vector Machine, Random Forest\n",
    "\n",
    "By: The _Learning Machines_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67f74b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b9c32c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data directory\n",
    "data_dir = '/Users/emily/Documents/NTU/2122SEMESTER1/MH4510/Project/'\n",
    "train_dir = data_dir+ 'Training/'\n",
    "test_dir = data_dir + 'Testing/'\n",
    "os.makedirs('./logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f273ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-defined data loading function\n",
    "def read_data(dir: str):\n",
    "    classes = {'no_tumor':0,'glioma_tumor':1,'pituitary_tumor':2,'meningioma_tumor':3}\n",
    "    images = []  #Img info\n",
    "    labels = []  #labels\n",
    "    for cls in classes:\n",
    "        pth = dir + cls\n",
    "        for j in os.listdir(pth):\n",
    "            img = cv2.imread(pth + '/' + j, 0)  #Read data in grey mode`\n",
    "            img = cv2.resize(img,(224,224))     #Same size as all models\n",
    "            images.append(img)\n",
    "            labels.append(classes[cls])\n",
    "\n",
    "    np.unique(labels)\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3bcd474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 2870 images, and 2870 corresponding labels for training.\n",
      "Successfully loaded 394 images, and 394 corresponding labels for testing.\n"
     ]
    }
   ],
   "source": [
    "# read training/validation data\n",
    "train_images, train_labels = read_data(train_dir)\n",
    "print(\"Successfully loaded\", len(train_images), \"images, and\", len(train_labels), \"corresponding labels for training.\")\n",
    "\n",
    "# read test data\n",
    "test_images, test_labels = read_data(test_dir)\n",
    "print(\"Successfully loaded\", len(test_images), \"images, and\", len(test_labels), \"corresponding labels for testing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68995f",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89c00fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten data\n",
    "train_images = train_images.reshape(len(train_images),-1)\n",
    "test_images = test_images.reshape(len(test_images),-1)\n",
    "\n",
    "# normalization (for KNN and SVM)\n",
    "train_images_std, test_images_std = map(preprocessing.StandardScaler().fit_transform, (train_images, test_images)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdf71ec",
   "metadata": {},
   "source": [
    "Model 1: KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ad03f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning\n",
    "opt_pca = 0\n",
    "opt_score = 0\n",
    "runlog = open(\"./logs/knn_runlog.txt\", \"a\")   #run log for parity check\n",
    "runlog.write(\"KNN Model Tuning Run Log\\n\\n\")\n",
    "\n",
    "# looping all pca parameters\n",
    "for var_ratio in np.arange(0.9, 0.96, step = 0.01):\n",
    "    runlog.write(\"current ratio: %2f\\r\\n\" %var_ratio)\n",
    "    \n",
    "    # apply pca to training data\n",
    "    train_images_r = PCA(n_components = var_ratio, whiten = True, random_state = 15).fit_transform(train_images_std)\n",
    "\n",
    "    # exhausive search for optimal parameters\n",
    "    knn = KNeighborsClassifier()\n",
    "    hyper_knn = dict(\n",
    "        n_neighbors = range(1, 3),\n",
    "        p = [1, 2]\n",
    "    )\n",
    "\n",
    "    knn_grid_search = GridSearchCV(\n",
    "        estimator = knn, \n",
    "        param_grid = hyper_knn, \n",
    "        scoring = 'f1_weighted',\n",
    "        cv = 5\n",
    "    ).fit(train_images_r, train_labels)\n",
    "\n",
    "    # update run log \n",
    "    runlog.write(json.dumps(knn_grid_search.best_params_))\n",
    "    runlog.write(\"\\nScore: %f\\r\\n\\n\" %knn_grid_search.best_score_)\n",
    "\n",
    "    #update optimal model globally\n",
    "    if knn_grid_search.best_score_ > opt_score:\n",
    "        opt_score = knn_grid_search.best_score_\n",
    "        opt_pca = var_ratio\n",
    "        knn_opt = knn_grid_search.best_estimator_\n",
    "        knn_opt_param = knn_grid_search.best_params_\n",
    "\n",
    "runlog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ad56775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN:\n",
      "Optimal pca parameter:\n",
      " 0.9 Optimal parameters\n",
      " {'n_neighbors': 1, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "# presenting the optimal model\n",
    "print(\"KNN:\\nOptimal pca parameter:\\n\", opt_pca, \"Optimal parameters\\n\", knn_opt_param)\n",
    "test_images_knn = PCA(n_components = opt_pca, whiten = True, random_state = 15).fit(train_images_std).transform(test_images_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad59435a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 score:\n",
      " 0.7740644848070707 \n",
      "Acuracy:\n",
      " 0.7944162436548223 \n",
      "Confusion matrix:\n",
      " [[105   0   0   0]\n",
      " [ 13  80   3   4]\n",
      " [  4  49  21   0]\n",
      " [  2   6   0 107]]\n"
     ]
    }
   ],
   "source": [
    "# predicting the Test set results\n",
    "pred_knn = knn_opt.predict(test_images_knn)\n",
    "f1_knn = f1_score(test_labels, pred_knn, average='weighted')\n",
    "acc_knn = accuracy_score(test_labels, pred_knn)\n",
    "cm_knn = confusion_matrix(test_labels, pred_knn)\n",
    "\n",
    "print(\"Weighted f1 score:\\n\", f1_knn, \"\\nAcuracy:\\n\", acc_knn, \"\\nConfusion matrix:\\n\", cm_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2ebd07",
   "metadata": {},
   "source": [
    "Model 2: Multiclass Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a4ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model tuning\n",
    "opt_pca = 0\n",
    "opt_score = 0\n",
    "runlog = open(\"./logs/svm_runlog.txt\", \"a\")   #run log for parity check\n",
    "\n",
    "# looping all pca parameters\n",
    "for var_ratio in np.arange(0.9, 0.96, step = 0.01):\n",
    "    runlog.write(\"current ratio: %2f\\r\\n\" %var_ratio)\n",
    "    \n",
    "    # apply pca to training data\n",
    "    train_images_r = PCA(n_components = var_ratio, whiten = True, random_state = 15).fit_transform(train_images_std)\n",
    "\n",
    "    # exhausive search for optimal parameters\n",
    "    svm = SVC()\n",
    "    hyper_svm = dict(\n",
    "        C = range(2, 5),\n",
    "        kernel = ['poly', 'rbf', 'sigmoid'],\n",
    "        degree = [4, 5]\n",
    "    )\n",
    "\n",
    "    svm_grid_search = GridSearchCV(\n",
    "        estimator = svm, \n",
    "        param_grid = hyper_svm, \n",
    "        scoring = 'f1_weighted', \n",
    "        cv = 5\n",
    "    ).fit(train_images_r, train_labels)\n",
    "\n",
    "    # update run log \n",
    "    runlog.write(json.dumps(svm_grid_search.best_params_))\n",
    "    runlog.write(\"\\nScore: %f\\r\\n\\n\" %svm_grid_search.best_score_)\n",
    "\n",
    "    #update optimal model globally\n",
    "    if svm_grid_search.best_score_ > opt_score:\n",
    "        opt_score = svm_grid_search.best_score_\n",
    "        opt_pca = var_ratio\n",
    "        svm_opt = svm_grid_search.best_estimator_\n",
    "        svm_opt_param = svm_grid_search.best_params_\n",
    "\n",
    "runlog.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "870fa664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Support Vector Machine:\n",
      "Optimal pca parameter:\n",
      " 0.9 Optimal parameters\n",
      " {'C': 3, 'degree': 4, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# presenting the optimal model\n",
    "print(\"Multiclass Support Vector Machine:\\nOptimal pca parameter:\\n\", opt_pca, \"Optimal parameters\\n\", svm_opt_param)\n",
    "test_images_svm = PCA(n_components = opt_pca, whiten = True, random_state = 15).fit(train_images_std).transform(test_images_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d680f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 score:\n",
      " 0.7075553342136243 \n",
      "Acuracy:\n",
      " 0.7106598984771574 \n",
      "Confusion matrix:\n",
      " [[ 80  21   2   2]\n",
      " [ 16  51  16  17]\n",
      " [  0  15  46  13]\n",
      " [  1  11   0 103]]\n"
     ]
    }
   ],
   "source": [
    "# predicting the Test set results\n",
    "pred_svm = svm_opt.predict(test_images_svm)\n",
    "f1_svm = f1_score(test_labels, pred_svm, average='weighted')\n",
    "acc_svm = accuracy_score(test_labels, pred_svm)\n",
    "cm_svm = confusion_matrix(test_labels, pred_svm)\n",
    "\n",
    "print(\"Weighted f1 score:\\n\", f1_svm, \"\\nAcuracy:\\n\", acc_svm, \"\\nConfusion matrix:\\n\", cm_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604b8684",
   "metadata": {},
   "source": [
    "Model 3: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ccca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# phase 1: model tuning by setting default pca as 0.9\n",
    "pca_90 = PCA(0.9, whiten=True, random_state=15).fit(train_images)\n",
    "train_images_rf, test_images_rf = map(pca_90.transform, (train_images, test_images))\n",
    "\n",
    "# tuning by exhausive grid search\n",
    "rf = RandomForestClassifier(oob_score = True, random_state = 15)\n",
    "\n",
    "hyper_rf = dict(\n",
    "    n_estimators = range(800, 850, 10),\n",
    "    min_samples_split = [2, 3, 5],\n",
    "    min_samples_leaf = [1, 2, 5],\n",
    "    min_impurity_decrease = [0, 0.01, 0.02]\n",
    ")\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator = rf,\n",
    "    param_grid = hyper_rf, \n",
    "    scoring = 'f1_weighted', \n",
    "    cv = 5\n",
    ").fit(train_images_rf, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d2119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presenting the optimal model\n",
    "print(\"Random Forest:\\nOptimal parameters under 90% pca:\\n\", rf_grid_search.best_params_)\n",
    "rf_opt = rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b171b951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 score:\n",
      " 0.739012863556102 \n",
      "Acuracy:\n",
      " 0.7868020304568528 \n",
      "Confusion matrix:\n",
      " [[105   0   0   0]\n",
      " [  5  20  13  62]\n",
      " [  0   2  71   1]\n",
      " [  1   0   0 114]]\n"
     ]
    }
   ],
   "source": [
    "# predicting the Test set results\n",
    "pred_rf = rf_opt.predict(test_images_rf)\n",
    "\n",
    "f1_rf = f1_score(test_labels, pred_rf, average='weighted')\n",
    "acc_rf = accuracy_score(test_labels, pred_rf)\n",
    "cm_rf = confusion_matrix(test_labels, pred_rf)\n",
    "print(\"Weighted f1 score:\\n\", f1_rf, \"\\nAcuracy:\\n\", acc_rf, \"\\nConfusion matrix:\\n\", cm_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e871a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pca =  0.9 \n",
      "\n",
      "0.631490671270384\n",
      "pca =  0.91 \n",
      "\n",
      "0.622681945120038\n",
      "pca =  0.92 \n",
      "\n",
      "0.6215295523605574\n",
      "pca =  0.93 \n",
      "\n",
      "0.6161921487014592\n",
      "pca =  0.9400000000000001 \n",
      "\n",
      "0.6222707391913734\n",
      "pca =  0.9500000000000001 \n",
      "\n",
      "0.616517841466945\n"
     ]
    }
   ],
   "source": [
    "# phase 2: pca tuning\n",
    "opt_pca = 0\n",
    "opt_cv = 0\n",
    "runlog = open(\"./logs/rf_runlog.txt\", \"a\")   #run log for parity check\n",
    "\n",
    "# looping all pca parameters\n",
    "for var_ratio in np.arange(0.9, 0.96, step = 0.01):\n",
    "    runlog.write(\"current ratio: %2f\\r\\n\" %var_ratio)\n",
    "    \n",
    "    # apply pca to training data\n",
    "    train_images_r = PCA(n_components = var_ratio, whiten = True, random_state = 15).fit_transform(train_images)\n",
    "\n",
    "    rf = RandomForestClassifier(820, oob_score = True, random_state = 15)\n",
    "    rf_cv_scores = cross_val_score(\n",
    "        rf, \n",
    "        train_images_r,\n",
    "        train_labels,\n",
    "        cv=5, \n",
    "        scoring='f1_weighted'\n",
    "    )\n",
    "    rf_cv = sum(rf_cv_scores)/5\n",
    "\n",
    "    runlog.write(\"cv score = %f\\r\\n\\n\" %rf_cv)\n",
    "\n",
    "    if(rf_cv > opt_cv):\n",
    "        opt_cv = rf_cv\n",
    "        opt_pca = var_ratio\n",
    "\n",
    "runlog.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6adf17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal pca parameter:\n",
      " 0.9\n"
     ]
    }
   ],
   "source": [
    "# presenting the optimal pca portion\n",
    "print(\"Optimal pca parameter:\\n\", opt_pca)\n",
    "train_images_rf, test_images_rf = map(PCA(n_components = opt_pca, whiten = True, random_state = 15).fit(train_images).transform, (train_images, test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02954764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted f1 score:\n",
      " 0.7331348683246979 \n",
      "Acuracy:\n",
      " 0.7791878172588832 \n",
      "Confusion matrix:\n",
      " [[105   0   0   0]\n",
      " [  4  20  13  63]\n",
      " [  0   2  68   4]\n",
      " [  1   0   0 114]]\n"
     ]
    }
   ],
   "source": [
    "# predicting the Test set results\n",
    "pred_rf = RandomForestClassifier(820, oob_score = True, random_state = 15).fit(train_images_rf, train_labels).predict(test_images_rf)\n",
    "\n",
    "f1_rf = f1_score(test_labels, pred_rf, average='weighted')\n",
    "acc_rf = accuracy_score(test_labels, pred_rf)\n",
    "cm_rf = confusion_matrix(test_labels, pred_rf)\n",
    "print(\"Weighted f1 score:\\n\", f1_rf, \"\\nAcuracy:\\n\", acc_rf, \"\\nConfusion matrix:\\n\", cm_rf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "12c989a2272087144a907f3af46e789b70a90abf7fd5b4372cac90cccd9eaa13"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
